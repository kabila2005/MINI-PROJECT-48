{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 21755,
          "databundleVersionId": 1475600,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30497,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install deepspeed"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:24:17.613531Z",
          "iopub.execute_input": "2023-06-12T13:24:17.613883Z",
          "iopub.status.idle": "2023-06-12T13:24:43.373505Z",
          "shell.execute_reply.started": "2023-06-12T13:24:17.613853Z",
          "shell.execute_reply": "2023-06-12T13:24:43.372359Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X9aBrHCfnPb",
        "outputId": "b2b9ab7d-7218-4ea0-8bef-89dab9fa8b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.14.4.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting ninja (from deepspeed)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.26.4)\n",
            "Collecting nvidia-ml-py (from deepspeed)\n",
            "  Downloading nvidia_ml_py-12.555.43-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.8.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.66.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->deepspeed)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->deepspeed)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->deepspeed)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->deepspeed)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->deepspeed)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->deepspeed)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->deepspeed)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->deepspeed)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->deepspeed)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->deepspeed)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->deepspeed)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
            "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-12.555.43-py3-none-any.whl (39 kB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.14.4-py3-none-any.whl size=1445396 sha256=85802f5708c87abf63cbfb84aaf32c6a0223339a088d60e86f35a6a1ce612ae3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/bc/a3/608e90bbb301848b78fd75d24d6d43ba3074de968fc0e397ac\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: nvidia-ml-py, ninja, hjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, deepspeed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import deepspeed as ds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pytorch_lightning as L\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from pytorch_lightning.utilities import CombinedLoader\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.io import read_image\n",
        "from torchvision.utils import make_grid, save_image\n",
        "_ = L.seed_everything(0, workers=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:24:43.377035Z",
          "iopub.execute_input": "2023-06-12T13:24:43.377436Z",
          "iopub.status.idle": "2023-06-12T13:24:59.15166Z",
          "shell.execute_reply.started": "2023-06-12T13:24:43.3774Z",
          "shell.execute_reply": "2023-06-12T13:24:59.150657Z"
        },
        "trusted": true,
        "id": "_j7T_hoSfnPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img(img_tensor, nrow, title=\"\"):\n",
        "    img_tensor = img_tensor.detach().cpu() * 0.5 + 0.5\n",
        "    img_grid = make_grid(img_tensor, nrow=nrow).permute(1, 2, 0)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(img_grid)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:24:59.152799Z",
          "iopub.execute_input": "2023-06-12T13:24:59.153835Z",
          "iopub.status.idle": "2023-06-12T13:24:59.159334Z",
          "shell.execute_reply.started": "2023-06-12T13:24:59.153807Z",
          "shell.execute_reply": "2023-06-12T13:24:59.158406Z"
        },
        "trusted": true,
        "id": "ZgvqpSKgfnPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTransform(object):\n",
        "    def __init__(self, load_dim=286, target_dim=256):\n",
        "        self.transform_train = T.Compose([\n",
        "            T.Resize((load_dim, load_dim), antialias=True),\n",
        "            T.RandomCrop((target_dim, target_dim)),\n",
        "            T.RandomHorizontalFlip(p=0.5),\n",
        "            T.ColorJitter(brightness=0.2, contrast=0.2,\n",
        "                          saturation=0.2, hue=0.1),\n",
        "        ])\n",
        "        self.transform = T.Resize((target_dim, target_dim), antialias=True)\n",
        "    def __call__(self, img, stage):\n",
        "        if stage == \"fit\":\n",
        "            img = self.transform_train(img)\n",
        "        else:\n",
        "            img = self.transform(img)\n",
        "        return img * 2 - 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:24:59.162543Z",
          "iopub.execute_input": "2023-06-12T13:24:59.163275Z",
          "iopub.status.idle": "2023-06-12T13:24:59.172309Z",
          "shell.execute_reply.started": "2023-06-12T13:24:59.163242Z",
          "shell.execute_reply": "2023-06-12T13:24:59.17143Z"
        },
        "trusted": true,
        "id": "pw_TZVR7fnPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, filenames, transform, stage):\n",
        "        self.filenames = filenames\n",
        "        self.transform = transform\n",
        "        self.stage = stage\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.filenames[idx]\n",
        "        img = read_image(img_name) / 255.0\n",
        "        return self.transform(img, stage=self.stage)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:24:59.173808Z",
          "iopub.execute_input": "2023-06-12T13:24:59.174138Z",
          "iopub.status.idle": "2023-06-12T13:24:59.18398Z",
          "shell.execute_reply.started": "2023-06-12T13:24:59.174108Z",
          "shell.execute_reply": "2023-06-12T13:24:59.183101Z"
        },
        "trusted": true,
        "id": "iPTL1iH3fnPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG = False\n",
        "\n",
        "DM_CONFIG = {\n",
        "    \"monet_dir\": os.path.join(\"/kaggle/input/gan-getting-started/monet_jpg\", \"*.jpg\"),\n",
        "    \"photo_dir\": os.path.join(\"/kaggle/input/gan-getting-started/photo_jpg\", \"*.jpg\"),\n",
        "\n",
        "    \"loader_config\": {\n",
        "        \"num_workers\": os.cpu_count(),\n",
        "        \"pin_memory\": torch.cuda.is_available(),\n",
        "    },\n",
        "    \"sample_size\": 5,\n",
        "    \"batch_size\": 1 if not DEBUG else 1,\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:24:59.185293Z",
          "iopub.execute_input": "2023-06-12T13:24:59.185677Z",
          "iopub.status.idle": "2023-06-12T13:24:59.210667Z",
          "shell.execute_reply.started": "2023-06-12T13:24:59.185646Z",
          "shell.execute_reply": "2023-06-12T13:24:59.209637Z"
        },
        "trusted": true,
        "id": "lxrvhF6bfnPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataModule(L.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        monet_dir,\n",
        "        photo_dir,\n",
        "        loader_config,\n",
        "        sample_size,\n",
        "        batch_size,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loader_config = loader_config\n",
        "        self.sample_size = sample_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # store file paths\n",
        "        self.monet_filenames = sorted(glob.glob(monet_dir))\n",
        "        self.photo_filenames = sorted(glob.glob(photo_dir))\n",
        "\n",
        "        # define transformations for image augmentation\n",
        "        self.transform = CustomTransform()\n",
        "\n",
        "    def setup(self, stage):\n",
        "        if stage == \"fit\":\n",
        "            self.train_monet = CustomDataset(self.monet_filenames, self.transform, stage)\n",
        "            self.train_photo = CustomDataset(self.photo_filenames, self.transform, stage)\n",
        "\n",
        "        if stage in [\"fit\", \"test\", \"predict\"]:\n",
        "            # to be used for test and prediction datasets as well\n",
        "            self.valid_photo = CustomDataset(self.photo_filenames, self.transform, None)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        loader_config = {\n",
        "            \"shuffle\": True,\n",
        "            \"drop_last\": True,\n",
        "            \"batch_size\": self.batch_size,\n",
        "            **self.loader_config,\n",
        "        }\n",
        "        loader_monet = DataLoader(self.train_monet, **loader_config)\n",
        "        loader_photo = DataLoader(self.train_photo, **loader_config)\n",
        "        loaders = {\"monet\": loader_monet, \"photo\": loader_photo}\n",
        "        return CombinedLoader(loaders, mode=\"max_size_cycle\")\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.valid_photo,\n",
        "            batch_size=self.sample_size,\n",
        "            **self.loader_config,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self.val_dataloader()\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.valid_photo,\n",
        "            batch_size=self.batch_size,\n",
        "            **self.loader_config,\n",
        "        )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:24:59.212188Z",
          "iopub.execute_input": "2023-06-12T13:24:59.21251Z",
          "iopub.status.idle": "2023-06-12T13:24:59.223352Z",
          "shell.execute_reply.started": "2023-06-12T13:24:59.21248Z",
          "shell.execute_reply": "2023-06-12T13:24:59.222355Z"
        },
        "trusted": true,
        "id": "z9mBmHbAfnPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Upsampling(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size=4,\n",
        "        stride=2,\n",
        "        padding=1,\n",
        "        output_padding=0,\n",
        "        dropout=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels,\n",
        "                               kernel_size=kernel_size, stride=stride,\n",
        "                               padding=padding, output_padding=output_padding, bias=False),\n",
        "            nn.InstanceNorm2d(out_channels, affine=True),\n",
        "        )\n",
        "        if dropout:\n",
        "            self.block.append(nn.Dropout(0.5))\n",
        "        self.block.append(nn.ReLU(True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:25:06.5491Z",
          "iopub.execute_input": "2023-06-12T13:25:06.54974Z",
          "iopub.status.idle": "2023-06-12T13:25:06.55858Z",
          "shell.execute_reply.started": "2023-06-12T13:25:06.549703Z",
          "shell.execute_reply": "2023-06-12T13:25:06.557576Z"
        },
        "trusted": true,
        "id": "fk4ybGxXfnQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, kernel_size=3, padding=1):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(padding),\n",
        "            Downsampling(in_channels, in_channels,\n",
        "                         kernel_size=kernel_size, stride=1, padding=0, lrelu=False),\n",
        "            nn.ReflectionPad2d(padding),\n",
        "            Downsampling(in_channels, in_channels,\n",
        "                         kernel_size=kernel_size, stride=1, padding=0, lrelu=None),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:25:06.559984Z",
          "iopub.execute_input": "2023-06-12T13:25:06.561117Z",
          "iopub.status.idle": "2023-06-12T13:25:06.569683Z",
          "shell.execute_reply.started": "2023-06-12T13:25:06.561085Z",
          "shell.execute_reply": "2023-06-12T13:25:06.568878Z"
        },
        "trusted": true,
        "id": "u60Nc1FqfnQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self, hid_channels, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.downsampling_path = nn.Sequential(\n",
        "            Downsampling(in_channels, hid_channels, norm=False), # 64x128x128\n",
        "            Downsampling(hid_channels, hid_channels*2), # 128x64x64\n",
        "            Downsampling(hid_channels*2, hid_channels*4), # 256x32x32\n",
        "            Downsampling(hid_channels*4, hid_channels*8), # 512x16x16\n",
        "            Downsampling(hid_channels*8, hid_channels*8), # 512x8x8\n",
        "            Downsampling(hid_channels*8, hid_channels*8), # 512x4x4\n",
        "            Downsampling(hid_channels*8, hid_channels*8), # 512x2x2\n",
        "            Downsampling(hid_channels*8, hid_channels*8, norm=False), # 512x1x1, instance norm does not work on 1x1\n",
        "        )\n",
        "        self.upsampling_path = nn.Sequential(\n",
        "            Upsampling(hid_channels*8, hid_channels*8, dropout=True), # (512+512)x2x2\n",
        "            Upsampling(hid_channels*16, hid_channels*8, dropout=True), # (512+512)x4x4\n",
        "            Upsampling(hid_channels*16, hid_channels*8, dropout=True), # (512+512)x8x8\n",
        "            Upsampling(hid_channels*16, hid_channels*8), # (512+512)x16x16\n",
        "            Upsampling(hid_channels*16, hid_channels*4), # (256+256)x32x32\n",
        "            Upsampling(hid_channels*8, hid_channels*2), # (128+128)x64x64\n",
        "            Upsampling(hid_channels*4, hid_channels), # (64+64)x128x128\n",
        "        )\n",
        "        self.feature_block = nn.Sequential(\n",
        "            nn.ConvTranspose2d(hid_channels*2, out_channels,\n",
        "                               kernel_size=4, stride=2, padding=1), # 3x256x256\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for down in self.downsampling_path:\n",
        "            x = down(x)\n",
        "            skips.append(x)\n",
        "        skips = reversed(skips[:-1])\n",
        "\n",
        "        for up, skip in zip(self.upsampling_path, skips):\n",
        "            x = up(x)\n",
        "            x = torch.cat([x, skip], dim=1)\n",
        "        return self.feature_block(x)\n",
        "\n",
        "class ResNetGenerator(nn.Module):\n",
        "    def __init__(self, hid_channels, in_channels, out_channels, num_resblocks):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ReflectionPad2d(3),\n",
        "            Downsampling(in_channels, hid_channels,\n",
        "                         kernel_size=7, stride=1, padding=0, lrelu=False), # 64x256x256\n",
        "            Downsampling(hid_channels, hid_channels*2, kernel_size=3, lrelu=False), # 128x128x128\n",
        "            Downsampling(hid_channels*2, hid_channels*4, kernel_size=3, lrelu=False), # 256x64x64\n",
        "            *[ResBlock(hid_channels*4) for _ in range(num_resblocks)], # 256x64x64\n",
        "            Upsampling(hid_channels*4, hid_channels*2, kernel_size=3, output_padding=1), # 128x128x128\n",
        "            Upsampling(hid_channels*2, hid_channels, kernel_size=3, output_padding=1), # 64x256x256\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(hid_channels, out_channels, kernel_size=7, stride=1, padding=0), # 3x256x256\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def get_gen(gen_name, hid_channels, num_resblocks, in_channels=3, out_channels=3):\n",
        "    if gen_name == \"unet\":\n",
        "        return UNetGenerator(hid_channels, in_channels, out_channels)\n",
        "    elif gen_name == \"resnet\":\n",
        "        return ResNetGenerator(hid_channels, in_channels, out_channels, num_resblocks)\n",
        "    else:\n",
        "        raise NotImplementedError(f\"Generator name '{gen_name}' not recognized.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:25:06.570807Z",
          "iopub.execute_input": "2023-06-12T13:25:06.571542Z",
          "iopub.status.idle": "2023-06-12T13:25:06.590909Z",
          "shell.execute_reply.started": "2023-06-12T13:25:06.571513Z",
          "shell.execute_reply": "2023-06-12T13:25:06.589949Z"
        },
        "trusted": true,
        "id": "O0-pnJx7fnQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, hid_channels, in_channels=3):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            Downsampling(in_channels, hid_channels, norm=False), # 64x128x128\n",
        "            Downsampling(hid_channels, hid_channels*2), # 128x64x64\n",
        "            Downsampling(hid_channels*2, hid_channels*4), # 256x32x32\n",
        "            Downsampling(hid_channels*4, hid_channels*8, stride=1), # 512x31x31\n",
        "            nn.Conv2d(hid_channels*8, 1, kernel_size=4, padding=1), # 1x30x30\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:25:06.592626Z",
          "iopub.execute_input": "2023-06-12T13:25:06.593037Z",
          "iopub.status.idle": "2023-06-12T13:25:06.605832Z",
          "shell.execute_reply.started": "2023-06-12T13:25:06.592965Z",
          "shell.execute_reply": "2023-06-12T13:25:06.604928Z"
        },
        "trusted": true,
        "id": "Rhw7_VXhfnQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageBuffer(object):\n",
        "    def __init__(self, buffer_size):\n",
        "        self.buffer_size = buffer_size\n",
        "        if self.buffer_size > 0:\n",
        "            # the current capacity of the buffer\n",
        "            self.curr_cap = 0\n",
        "            # initialize buffer as empty list\n",
        "            self.buffer = []\n",
        "\n",
        "    def __call__(self, imgs):\n",
        "        # the buffer is not used\n",
        "        if self.buffer_size == 0:\n",
        "            return imgs\n",
        "\n",
        "        return_imgs = []\n",
        "        for img in imgs:\n",
        "            img = img.unsqueeze(dim=0)\n",
        "\n",
        "            # fill buffer to maximum capacity\n",
        "            if self.curr_cap < self.buffer_size:\n",
        "                self.curr_cap += 1\n",
        "                self.buffer.append(img)\n",
        "                return_imgs.append(img)\n",
        "            else:\n",
        "                p = np.random.uniform(low=0., high=1.)\n",
        "\n",
        "                # swap images between input and buffer with probability 0.5\n",
        "                if p > 0.5:\n",
        "                    idx = np.random.randint(low=0, high=self.buffer_size)\n",
        "                    tmp = self.buffer[idx].clone()\n",
        "                    self.buffer[idx] = img\n",
        "                    return_imgs.append(tmp)\n",
        "                else:\n",
        "                    return_imgs.append(img)\n",
        "        return torch.cat(return_imgs, dim=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:25:06.607248Z",
          "iopub.execute_input": "2023-06-12T13:25:06.607793Z",
          "iopub.status.idle": "2023-06-12T13:25:06.622427Z",
          "shell.execute_reply.started": "2023-06-12T13:25:06.607761Z",
          "shell.execute_reply": "2023-06-12T13:25:06.621563Z"
        },
        "trusted": true,
        "id": "vvIKxf6CfnQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the CycleGAN model**"
      ],
      "metadata": {
        "id": "O96mh-3pfnQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_CONFIG = {\n",
        "    # the type of generator, and the number of residual blocks if ResNet generator is used\n",
        "    \"gen_name\": \"unet\", # types: 'unet', 'resnet'\n",
        "    \"num_resblocks\": 6,\n",
        "    # the number of filters in the first layer for the generators and discriminators\n",
        "    \"hid_channels\": 64,\n",
        "    # using DeepSpeed's FusedAdam (currently GPU only) is slightly faster\n",
        "    \"optimizer\": ds.ops.adam.FusedAdam if torch.cuda.is_available() else torch.optim.Adam,\n",
        "    # the learning rate and beta parameters for the Adam optimizer\n",
        "    \"lr\": 2e-4,\n",
        "    \"betas\": (0.5, 0.999),\n",
        "    # the weights used in the identity loss and cycle loss\n",
        "    \"lambda_idt\": 0.5,\n",
        "    \"lambda_cycle\": (10, 10), # (MPM direction, PMP direction)\n",
        "    # the size of the buffer that stores previously generated images\n",
        "    \"buffer_size\": 100,\n",
        "    # the number of epochs for training\n",
        "    \"num_epochs\": 18 if not DEBUG else 2,\n",
        "    # the number of epochs before starting the learning rate decay\n",
        "    \"decay_epochs\": 18 if not DEBUG else 1,\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:25:06.625116Z",
          "iopub.execute_input": "2023-06-12T13:25:06.625397Z",
          "iopub.status.idle": "2023-06-12T13:25:06.63479Z",
          "shell.execute_reply.started": "2023-06-12T13:25:06.625375Z",
          "shell.execute_reply": "2023-06-12T13:25:06.633955Z"
        },
        "trusted": true,
        "id": "5n1XDUutfnQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleGAN(L.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        gen_name,\n",
        "        num_resblocks,\n",
        "        hid_channels,\n",
        "        optimizer,\n",
        "        lr,\n",
        "        betas,\n",
        "        lambda_idt,\n",
        "        lambda_cycle,\n",
        "        buffer_size,\n",
        "        num_epochs,\n",
        "        decay_epochs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(ignore=[\"optimizer\"])\n",
        "        self.optimizer = optimizer\n",
        "        self.automatic_optimization = False\n",
        "\n",
        "        # define generators and discriminators\n",
        "        self.gen_PM = get_gen(gen_name, hid_channels, num_resblocks)\n",
        "        self.gen_MP = get_gen(gen_name, hid_channels, num_resblocks)\n",
        "        self.disc_M = Discriminator(hid_channels)\n",
        "        self.disc_P = Discriminator(hid_channels)\n",
        "\n",
        "        # initialize buffers to store fake images\n",
        "        self.buffer_fake_M = ImageBuffer(buffer_size)\n",
        "        self.buffer_fake_P = ImageBuffer(buffer_size)\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.gen_PM(img)\n",
        "\n",
        "    def init_weights(self):\n",
        "        def init_fn(m):\n",
        "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.InstanceNorm2d)):\n",
        "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "        for net in [self.gen_PM, self.gen_MP, self.disc_M, self.disc_P]:\n",
        "            net.apply(init_fn)\n",
        "\n",
        "    def setup(self, stage):\n",
        "        if stage == \"fit\":\n",
        "            self.init_weights()\n",
        "            print(\"Model initialized.\")\n",
        "\n",
        "    def get_lr_scheduler(self, optimizer):\n",
        "        def lr_lambda(epoch):\n",
        "            len_decay_phase = self.hparams.num_epochs - self.hparams.decay_epochs + 1.0\n",
        "            curr_decay_step = max(0, epoch - self.hparams.decay_epochs + 1.0)\n",
        "            val = 1.0 - curr_decay_step / len_decay_phase\n",
        "            return max(0.0, val)\n",
        "\n",
        "        return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt_config = {\n",
        "            \"lr\": self.hparams.lr,\n",
        "            \"betas\": self.hparams.betas,\n",
        "        }\n",
        "        opt_gen = self.optimizer(\n",
        "            list(self.gen_PM.parameters()) + list(self.gen_MP.parameters()),\n",
        "            **opt_config,\n",
        "        )\n",
        "        opt_disc = self.optimizer(\n",
        "            list(self.disc_M.parameters()) + list(self.disc_P.parameters()),\n",
        "            **opt_config,\n",
        "        )\n",
        "        optimizers = [opt_gen, opt_disc]\n",
        "        schedulers = [self.get_lr_scheduler(opt) for opt in optimizers]\n",
        "        return optimizers, schedulers\n",
        "\n",
        "    def adv_criterion(self, y_hat, y):\n",
        "        return F.mse_loss(y_hat, y)\n",
        "\n",
        "    def recon_criterion(self, y_hat, y):\n",
        "        return F.l1_loss(y_hat, y)\n",
        "\n",
        "    def get_adv_loss(self, fake, disc):\n",
        "        fake_hat = disc(fake)\n",
        "        real_labels = torch.ones_like(fake_hat)\n",
        "        adv_loss = self.adv_criterion(fake_hat, real_labels)\n",
        "        return adv_loss\n",
        "\n",
        "    def get_idt_loss(self, real, idt, lambda_cycle):\n",
        "        idt_loss = self.recon_criterion(idt, real)\n",
        "        return self.hparams.lambda_idt * lambda_cycle * idt_loss\n",
        "\n",
        "    def get_cycle_loss(self, real, recon, lambda_cycle):\n",
        "        cycle_loss = self.recon_criterion(recon, real)\n",
        "        return lambda_cycle * cycle_loss\n",
        "\n",
        "    def get_gen_loss(self):\n",
        "        # calculate adversarial loss\n",
        "        adv_loss_PM = self.get_adv_loss(self.fake_M, self.disc_M)\n",
        "        adv_loss_MP = self.get_adv_loss(self.fake_P, self.disc_P)\n",
        "        total_adv_loss = adv_loss_PM + adv_loss_MP\n",
        "\n",
        "        # calculate identity loss\n",
        "        lambda_cycle = self.hparams.lambda_cycle\n",
        "        idt_loss_MM = self.get_idt_loss(self.real_M, self.idt_M, lambda_cycle[0])\n",
        "        idt_loss_PP = self.get_idt_loss(self.real_P, self.idt_P, lambda_cycle[1])\n",
        "        total_idt_loss = idt_loss_MM + idt_loss_PP\n",
        "\n",
        "        # calculate cycle loss\n",
        "        cycle_loss_MPM = self.get_cycle_loss(self.real_M, self.recon_M, lambda_cycle[0])\n",
        "        cycle_loss_PMP = self.get_cycle_loss(self.real_P, self.recon_P, lambda_cycle[1])\n",
        "        total_cycle_loss = cycle_loss_MPM + cycle_loss_PMP\n",
        "\n",
        "        # combine losses\n",
        "        gen_loss = total_adv_loss + total_idt_loss + total_cycle_loss\n",
        "        return gen_loss\n",
        "\n",
        "    def get_disc_loss(self, real, fake, disc):\n",
        "        # calculate loss on real images\n",
        "        real_hat = disc(real)\n",
        "        real_labels = torch.ones_like(real_hat)\n",
        "        real_loss = self.adv_criterion(real_hat, real_labels)\n",
        "\n",
        "        # calculate loss on fake images\n",
        "        fake_hat = disc(fake.detach())\n",
        "        fake_labels = torch.zeros_like(fake_hat)\n",
        "        fake_loss = self.adv_criterion(fake_hat, fake_labels)\n",
        "\n",
        "        # combine losses\n",
        "        disc_loss = (fake_loss + real_loss) * 0.5\n",
        "        return disc_loss\n",
        "\n",
        "    def get_disc_loss_M(self):\n",
        "        fake_M = self.buffer_fake_M(self.fake_M)\n",
        "        return self.get_disc_loss(self.real_M, fake_M, self.disc_M)\n",
        "\n",
        "    def get_disc_loss_P(self):\n",
        "        fake_P = self.buffer_fake_P(self.fake_P)\n",
        "        return self.get_disc_loss(self.real_P, fake_P, self.disc_P)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        self.real_M = batch[\"monet\"]\n",
        "        self.real_P = batch[\"photo\"]\n",
        "        opt_gen, opt_disc = self.optimizers()\n",
        "\n",
        "        # generate fake images\n",
        "        self.fake_M = self.gen_PM(self.real_P)\n",
        "        self.fake_P = self.gen_MP(self.real_M)\n",
        "\n",
        "        # generate identity images\n",
        "        self.idt_M = self.gen_PM(self.real_M)\n",
        "        self.idt_P = self.gen_MP(self.real_P)\n",
        "\n",
        "        # reconstruct images\n",
        "        self.recon_M = self.gen_PM(self.fake_P)\n",
        "        self.recon_P = self.gen_MP(self.fake_M)\n",
        "\n",
        "        # train generators\n",
        "        self.toggle_optimizer(opt_gen)\n",
        "        gen_loss = self.get_gen_loss()\n",
        "        opt_gen.zero_grad()\n",
        "        self.manual_backward(gen_loss)\n",
        "        opt_gen.step()\n",
        "        self.untoggle_optimizer(opt_gen)\n",
        "\n",
        "        # train discriminators\n",
        "        self.toggle_optimizer(opt_disc)\n",
        "        disc_loss_M = self.get_disc_loss_M()\n",
        "        disc_loss_P = self.get_disc_loss_P()\n",
        "        opt_disc.zero_grad()\n",
        "        self.manual_backward(disc_loss_M)\n",
        "        self.manual_backward(disc_loss_P)\n",
        "        opt_disc.step()\n",
        "        self.untoggle_optimizer(opt_disc)\n",
        "\n",
        "        # record training losses\n",
        "        metrics = {\n",
        "            \"gen_loss\": gen_loss,\n",
        "            \"disc_loss_M\": disc_loss_M,\n",
        "            \"disc_loss_P\": disc_loss_P,\n",
        "        }\n",
        "        self.log_dict(metrics, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self.display_results(batch, batch_idx, \"validate\")\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        self.display_results(batch, batch_idx, \"test\")\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        return self(batch)\n",
        "\n",
        "    def display_results(self, batch, batch_idx, stage):\n",
        "        real_P = batch\n",
        "        fake_M = self(real_P)\n",
        "\n",
        "        if stage == \"validate\":\n",
        "            title = f\"Epoch {self.current_epoch+1}: Photo-to-Monet Translation\"\n",
        "        else:\n",
        "            title = f\"Sample {batch_idx+1}: Photo-to-Monet Translation\"\n",
        "\n",
        "        show_img(\n",
        "            torch.cat([real_P, fake_M], dim=0),\n",
        "            nrow=len(real_P),\n",
        "            title=title,\n",
        "        )\n",
        "\n",
        "    def on_train_epoch_start(self):\n",
        "        # record learning rates\n",
        "        curr_lr = self.lr_schedulers()[0].get_last_lr()[0]\n",
        "        self.log(\"lr\", curr_lr, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        # update learning rates\n",
        "        for sch in self.lr_schedulers():\n",
        "            sch.step()\n",
        "\n",
        "        # print current state of epoch\n",
        "        logged_values = self.trainer.progress_bar_metrics\n",
        "        print(\n",
        "            f\"Epoch {self.current_epoch+1}\",\n",
        "            *[f\"{k}: {v:.5f}\" for k, v in logged_values.items()],\n",
        "            sep=\" - \",\n",
        "        )\n",
        "\n",
        "    def on_train_end(self):\n",
        "        print(\"Training ended.\")\n",
        "\n",
        "    def on_predict_epoch_end(self):\n",
        "        predictions = self.trainer.predict_loop.predictions\n",
        "        num_batches = len(predictions)\n",
        "        batch_size = predictions[0].shape[0]\n",
        "        last_batch_diff = batch_size - predictions[-1].shape[0]\n",
        "        print(f\"Number of images generated: {num_batches*batch_size-last_batch_diff}.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:25:06.636397Z",
          "iopub.execute_input": "2023-06-12T13:25:06.636712Z",
          "iopub.status.idle": "2023-06-12T13:25:06.675406Z",
          "shell.execute_reply.started": "2023-06-12T13:25:06.636683Z",
          "shell.execute_reply": "2023-06-12T13:25:06.674273Z"
        },
        "trusted": true,
        "id": "iIkXufusfnQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_CONFIG = {\n",
        "    \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "\n",
        "    # train on 16-bit precision\n",
        "    \"precision\": \"16-mixed\" if torch.cuda.is_available() else 32,\n",
        "\n",
        "    # train on single GPU\n",
        "    \"devices\": 1,\n",
        "\n",
        "    # save checkpoint only for last epoch by default\n",
        "    \"enable_checkpointing\": True,\n",
        "\n",
        "    # disable logging for simplicity\n",
        "    \"logger\": False,\n",
        "\n",
        "    # the number of epochs for training (we limit the number of train/predict batches during debugging)\n",
        "    \"max_epochs\": MODEL_CONFIG[\"num_epochs\"],\n",
        "    \"limit_train_batches\": 1.0 if not DEBUG else 2,\n",
        "    \"limit_predict_batches\": 1.0 if not DEBUG else 5,\n",
        "\n",
        "    # the maximum amount of time for training, in case we exceed run-time of 5 hours\n",
        "    \"max_time\": {\"hours\": 4, \"minutes\": 55},\n",
        "\n",
        "    # use a small subset of photos for validation/testing (we limit here for flexibility)\n",
        "    \"limit_val_batches\": 1,\n",
        "    \"limit_test_batches\": 5,\n",
        "\n",
        "    # disable sanity check before starting the training routine\n",
        "    \"num_sanity_val_steps\": 0,\n",
        "\n",
        "    # the frequency to visualize the progress of adding Monet style\n",
        "    \"check_val_every_n_epoch\": 6 if not DEBUG else 1,\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:25:06.676815Z",
          "iopub.execute_input": "2023-06-12T13:25:06.67726Z",
          "iopub.status.idle": "2023-06-12T13:25:06.693518Z",
          "shell.execute_reply.started": "2023-06-12T13:25:06.677225Z",
          "shell.execute_reply": "2023-06-12T13:25:06.692597Z"
        },
        "trusted": true,
        "id": "L2emJBttfnQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm = CustomDataModule(**DM_CONFIG)\n",
        "model = CycleGAN(**MODEL_CONFIG)\n",
        "trainer = L.Trainer(**TRAIN_CONFIG)\n",
        "trainer.fit(model, datamodule=dm)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T13:25:06.694776Z",
          "iopub.execute_input": "2023-06-12T13:25:06.695278Z",
          "iopub.status.idle": "2023-06-12T18:18:29.79928Z",
          "shell.execute_reply.started": "2023-06-12T13:25:06.695248Z",
          "shell.execute_reply": "2023-06-12T18:18:29.798243Z"
        },
        "trusted": true,
        "id": "xT0f6_DgfnQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = trainer.test(model, datamodule=dm)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T18:18:29.801413Z",
          "iopub.execute_input": "2023-06-12T18:18:29.801791Z",
          "iopub.status.idle": "2023-06-12T18:18:34.559338Z",
          "shell.execute_reply.started": "2023-06-12T18:18:29.801754Z",
          "shell.execute_reply": "2023-06-12T18:18:34.558109Z"
        },
        "trusted": true,
        "id": "iDwVFg-2fnQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(model, datamodule=dm)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T18:18:34.560945Z",
          "iopub.execute_input": "2023-06-12T18:18:34.561315Z",
          "iopub.status.idle": "2023-06-12T18:19:48.206598Z",
          "shell.execute_reply.started": "2023-06-12T18:18:34.561279Z",
          "shell.execute_reply": "2023-06-12T18:19:48.205465Z"
        },
        "trusted": true,
        "id": "yQwhs29qfnQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"../images\", exist_ok=True)\n",
        "idx = 0\n",
        "for tensor in predictions:\n",
        "    for monet in tensor:\n",
        "        save_image(\n",
        "            monet.float().squeeze() * 0.5 + 0.5,\n",
        "            fp=f\"../images/{idx}.jpg\",\n",
        "        )\n",
        "        idx += 1\n",
        "\n",
        "shutil.make_archive(\"/kaggle/working/images\", \"zip\", \"/kaggle/images\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T18:36:39.881653Z",
          "iopub.execute_input": "2023-06-12T18:36:39.88211Z",
          "iopub.status.idle": "2023-06-12T18:37:04.314631Z",
          "shell.execute_reply.started": "2023-06-12T18:36:39.882077Z",
          "shell.execute_reply": "2023-06-12T18:37:04.313645Z"
        },
        "trusted": true,
        "id": "J7MoZkCGfnQs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}